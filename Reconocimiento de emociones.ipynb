{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0aec302c",
   "metadata": {},
   "source": [
    "# Codigo para capturar las imagenes de las emociones\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c3cfa1-294c-4c88-8cc8-3ef05aa0f543",
   "metadata": {},
   "source": [
    "### Josué Montalván Zavala"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6aacdb-b550-4d4d-b212-0d2b279e7923",
   "metadata": {},
   "source": [
    "##### Captura de frames para guardar y clasificar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53950f02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import math \n",
    "\n",
    "haar_cascade_path = cv.data.haarcascades + 'haarcascade_frontalface_alt.xml'\n",
    "rostro_cascade = cv.CascadeClassifier(haar_cascade_path)\n",
    "\n",
    "cap = cv.VideoCapture(0)\n",
    "i = 0 \n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    rostros = rostro_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    for (x, y, w, h) in rostros:\n",
    "        # Extraer el rostro de la imagen en escala de grises\n",
    "        rostro_gray = gray[y:y+h, x:x+w]\n",
    "        rostro_gray = cv.resize(rostro_gray, (48, 48), interpolation=cv.INTER_AREA)\n",
    "        cv.imwrite(f'C:/Users/crazu/Documents/Inteligencia artificial/Emociones/Tristeza/t{i}.png', rostro_gray)\n",
    "        \n",
    "    cv.imshow('rostros', frame)\n",
    "    i += 1\n",
    "    k = cv.waitKey(1)\n",
    "    if k == 27:  # Presiona 'Esc' para salir\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ece19f",
   "metadata": {},
   "source": [
    " # Escritura del xml de entrenamiento/reconocimiento\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c73937",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def obtenerModelo(method,facesData,labels):\n",
    "    \n",
    "    if method == 'EigenFaces': emotion_recognizer = cv2.face.EigenFaceRecognizer_create()\n",
    "    # Entrenando el reconocedor de rostros\n",
    "    print(\"Entrenando ( \"+method+\" )...\")\n",
    "    inicio = time.time()\n",
    "    emotion_recognizer.train(facesData, np.array(labels))\n",
    "    tiempoEntrenamiento = time.time()-inicio\n",
    "    print(\"Tiempo de entrenamiento ( \"+method+\" ): \", tiempoEntrenamiento)\n",
    "\n",
    "    # Almacenando el modelo obtenido\n",
    "    emotion_recognizer.write(\"modelo\"+method+\".xml\")\n",
    "\n",
    "dataPath = '/Users/crazu/Documents/Inteligencia artificial/Emociones/' #Cambia a la ruta donde hayas almacenado Data\n",
    "emotionsList = os.listdir(dataPath)\n",
    "print('Lista de emociones: ', emotionsList)\n",
    "\n",
    "labels = []\n",
    "facesData = []\n",
    "label = 0\n",
    "\n",
    "for nameDir in emotionsList:\n",
    "    emotionsPath = dataPath + '/' + nameDir\n",
    "\n",
    "    for fileName in os.listdir(emotionsPath):\n",
    "        #print('Rostros: ', nameDir + '/' + fileName)\n",
    "        labels.append(label)\n",
    "        facesData.append(cv2.imread(emotionsPath+'/'+fileName,0))\n",
    "        #image = cv2.imread(emotionsPath+'/'+fileName,0)\n",
    "        #cv2.imshow('image',image)\n",
    "        #cv2.waitKey(10)\n",
    "    label = label + 1\n",
    "\n",
    "obtenerModelo('EigenFaces',facesData,labels)\n",
    "#obtenerModelo('FisherFaces',facesData,labels)\n",
    "#obtenerModelo('LBPH',facesData,labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6100b047",
   "metadata": {},
   "source": [
    "# Reconocimiento de las emociones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70465db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "method = 'EigenFaces'\n",
    "if method == 'EigenFaces':\n",
    "    emotion_recognizer = cv2.face.EigenFaceRecognizer_create()\n",
    "\n",
    "emotion_recognizer.read('modelo' + method + '.xml')\n",
    "\n",
    "\n",
    "dataPath = '/Users/crazu/Documents/Inteligencia artificial/Emociones/' \n",
    "imagePaths = os.listdir(dataPath)\n",
    "print('imagePaths=', imagePaths)\n",
    "\n",
    "cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)\n",
    "\n",
    "faceClassif = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_alt.xml')\n",
    "\n",
    "while True:\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if ret == False:\n",
    "        break\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    auxFrame = gray.copy()\n",
    "\n",
    "    nFrame = cv2.hconcat([frame, np.zeros((480, 300, 3), dtype=np.uint8)])\n",
    "\n",
    "    faces = faceClassif.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        rostro = auxFrame[y:y + h, x:x + w]\n",
    "        rostro = cv2.resize(rostro, (48, 48), interpolation=cv2.INTER_CUBIC)\n",
    "        result = emotion_recognizer.predict(rostro)\n",
    "\n",
    "        cv2.putText(frame, '{}'.format(imagePaths[result[0]]), (x, y - 5), 1, 1.3, (255, 255, 0), 1, cv2.LINE_AA)\n",
    "\n",
    "        # EigenFaces\n",
    "        if method == 'EigenFaces':\n",
    "            if result[1] < 5700:\n",
    "                cv2.putText(frame, '{}'.format(imagePaths[result[0]]), (x, y - 25), 2, 1.1, (0, 255, 0), 1, cv2.LINE_AA)\n",
    "                cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "                nFrame = cv2.hconcat([frame])\n",
    "            else:\n",
    "                cv2.putText(frame, 'No identificado', (x, y - 20), 2, 0.8, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "                cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "                nFrame = cv2.hconcat([frame, np.zeros((480, 300, 3), dtype=np.uint8)])\n",
    "\n",
    "    cv2.imshow('nFrame', nFrame)\n",
    "    k = cv2.waitKey(1)\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f799a061-c17c-405d-8779-f357fca9fd7b",
   "metadata": {},
   "source": [
    "# Renombrar imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6434aebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# Directorio de entrada y salida\n",
    "input_dir = 'C:\\\\Users\\\\crazu\\\\Downloads\\\\triste'\n",
    "output_dir = 'C:/Users/crazu/Documents/Carpeta IA/IA-Josu-Montalv-n/Emociones/EEnojo'\n",
    "\n",
    "# Crear la carpeta de salida si no existe\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Función para generar un nuevo nombre de archivo\n",
    "def generate_new_filename(old_filename, prefix='BW_', suffix=''):\n",
    "    name, ext = os.path.splitext(old_filename)\n",
    "    return f\"{prefix}{name}{suffix}{ext}\"\n",
    "\n",
    "# Obtener lista de archivos en el directorio de entrada\n",
    "for filename in os.listdir(input_dir):\n",
    "    # Comprobar que el archivo es una imagen\n",
    "    if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):\n",
    "        # Ruta completa del archivo\n",
    "        file_path = os.path.join(input_dir, filename)\n",
    "        # Abrir la imagen\n",
    "        with Image.open(file_path) as img:\n",
    "            # Convertir a blanco y negro\n",
    "            bw_img = img.convert('L')\n",
    "            # Generar nuevo nombre de \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd13d23-68eb-4787-829d-e40ed5c37867",
   "metadata": {},
   "source": [
    "# Renombrar y en blanco y negro "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9448ef8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "def resize_and_convert_to_bw(input_folder, output_folder, size=(48, 48), prefix='BW_', suffix=''):\n",
    "    # Crear la carpeta de salida si no existe\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Contador para el número de imágenes procesadas\n",
    "    num_images_processed = 0\n",
    "\n",
    "    # Función para generar un nuevo nombre de archivo\n",
    "    def generate_new_filename(old_filename):\n",
    "        name, ext = os.path.splitext(old_filename)\n",
    "        return f\"{prefix}{name}{suffix}{ext}\"\n",
    "\n",
    "    # Recorrer todos los archivos en la carpeta de entrada\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.lower().endswith((\".jpg\", \".png\", \".jpeg\")):\n",
    "            img_path = os.path.join(input_folder, filename)\n",
    "            img = cv2.imread(img_path)\n",
    "\n",
    "            if img is not None:\n",
    "                resized_img = cv2.resize(img, size)\n",
    "                bw_img = cv2.cvtColor(resized_img, cv2.COLOR_BGR2GRAY)\n",
    "                new_filename = generate_new_filename(filename)\n",
    "                output_path = os.path.join(output_folder, new_filename)\n",
    "                cv2.imwrite(output_path, bw_img)\n",
    "                num_images_processed += 1\n",
    "            else:\n",
    "                print(f\"No se pudo leer la imagen {filename}\")\n",
    "        else:\n",
    "            print(f\"El archivo {filename} no es una imagen soportada, se omitirá\")\n",
    "\n",
    "    print(f\"Proceso finalizado: {num_images_processed} imágenes redimensionadas, convertidas a blanco y negro, y guardadas en {output_folder}\")\n",
    "\n",
    "input_folder = 'C:\\\\Users\\\\crazu\\\\Downloads\\\\triste'  # Cambia esto a la ruta de tu carpeta de entrada\n",
    "output_folder = 'C:/Users/crazu/Documents/Carpeta IA/IA-Josu-Montalv-n/Emociones/EEnojo'  # Cambia esto a la ruta de tu carpeta de salida\n",
    "\n",
    "resize_and_convert_to_bw(input_folder, output_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af33959b-7f3f-4b32-9ce9-b511f4897fed",
   "metadata": {},
   "source": [
    "# Deteccion de emociones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0908b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import os \n",
    "\n",
    "faceRecognizer = cv.face.LBPHFaceRecognizer_create()\n",
    "faceRecognizer.read(\"C:\\Users\\\\crazu\\\\Documents\\\\Inteligencia artificial\\\\modeloEigenFaces.xml\")\n",
    "faces = [\"Enojo\",\"Feliciadad\",\"Sorpresa\",\"Tristeza\"]\n",
    "cap = cv.VideoCapture(0)\n",
    "rostro = cv.CascadeClassifier('C:/Users/crazu/Documents/Inteligencia artificial/haarcascade_frontalface_alt.xml')\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if ret == False: break\n",
    "    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    cpGray = gray.copy()\n",
    "    rostros = rostro.detectMultiScale(gray, 1.3, 3)\n",
    "    for(x, y, w, h) in rostros:\n",
    "        frame2 = cpGray[y:y+h, x:x+w]\n",
    "        frame2 = cv.resize(frame2,  (48,48), interpolation=cv.INTER_CUBIC)\n",
    "        result = faceRecognizer.predict(frame2)\n",
    "        cv.putText(frame, '{}'.format(result), (x,y-20), 1,3.3, (255,255,0), 1, cv.LINE_AA)\n",
    "        if result[1] < 100:\n",
    "            cv.putText(frame,'{}'.format(faces[result[0]]),(x,y-25),2,1.1,(0,255,0),1,cv.LINE_AA)\n",
    "            cv.rectangle(frame, (x,y),(x+w,y+h),(0,255,0),2)\n",
    "        else:\n",
    "            cv.putText(frame,'Desconocido',(x,y-20),2,0.8,(0,0,255),1,cv.LINE_AA)\n",
    "            cv.rectangle(frame, (x,y),(x+w,y+h),(0,0,255),2) \n",
    "    cv.imshow('frame', frame)\n",
    "    k = cv.waitKey(1)\n",
    "    if k == 27:\n",
    "        break\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad4735a5-663d-4c01-921a-31e784fdde20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imagePaths= ['Enojo', 'Felicidad', 'Sorpresa', 'Tristeza']\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# ----------- Métodos usados para el entrenamiento y lectura del modelo ----------\n",
    "method = 'EigenFaces'\n",
    "\n",
    "if method == 'EigenFaces':\n",
    "    emotion_recognizer = cv2.face.EigenFaceRecognizer_create()\n",
    "\n",
    "emotion_recognizer.read('modelo'+method+'.xml')\n",
    "# --------------------------------------------------------------------------------\n",
    "\n",
    "dataPath = 'C:\\\\Users\\\\crazu\\\\Documents\\\\Inteligencia artificial\\\\Emociones'  # Cambia a la ruta donde hayas almacenado Data\n",
    "imagePaths = os.listdir(dataPath)\n",
    "print('imagePaths=', imagePaths)\n",
    "\n",
    "cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)\n",
    "\n",
    "faceClassif = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_alt.xml')\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if ret == False: break\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    auxFrame = gray.copy()\n",
    "\n",
    "    nFrame = cv2.hconcat([frame, np.zeros((480, 300, 3), dtype=np.uint8)])\n",
    "\n",
    "    faces = faceClassif.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        rostro = auxFrame[y:y + h, x:x + w]\n",
    "        rostro = cv2.resize(rostro, (48, 48), interpolation=cv2.INTER_CUBIC)\n",
    "        result = emotion_recognizer.predict(rostro)\n",
    "\n",
    "        cv2.putText(frame, '{}'.format(result), (x, y - 5), 1, 1.3, (255, 255, 0), 1, cv2.LINE_AA)\n",
    "\n",
    "        if result[1] < 5700:\n",
    "            cv2.putText(frame, '{}'.format(imagePaths[result[0]]), (x, y - 25), 2, 1.1, (0, 255, 0), 1, cv2.LINE_AA)\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "            nFrame = cv2.hconcat([frame])\n",
    "        else:\n",
    "            cv2.putText(frame, 'No identificado', (x, y - 20), 2, 0.8, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "            nFrame = cv2.hconcat([frame, np.zeros((480, 300, 3), dtype=np.uint8)])\n",
    "\n",
    "    cv2.imshow('nFrame', nFrame)\n",
    "    k = cv2.waitKey(1)\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e495698-6cc0-4430-a226-b2f1e5377135",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
